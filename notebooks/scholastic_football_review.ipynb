{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Notre Dame Scholastic Football Review\n",
    "\n",
    "From the [University Archives](http://archives.nd.edu/digital/):\n",
    "- \"The Notre Dame Scholastic published reviews of the football season starting in 1901. In 1910 a separate publication covered the \"Gridiron Season\" and from 1919 to 1921 a Football Review provided competition for the Scholastic. From 1924 to 1932 the Football Review prevailed as the Scholastic provided little or no commentary. In later years the Scholastic generally published its own special issue on the football season, though Irish Eye took over for a time in the 1980s.\"\n",
    "- [Notre Dame Football Review, 1901 - 2010](http://archives.nd.edu/Football/)\n",
    "\n",
    "This Jupyter Notebook inclues codes + comments that downloads all football review PDFs, and also matches publication titles to file names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries, Load URL, and Create Beautiful Soup Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load url, create beautifulsoup object\n",
    "page = requests.get('http://archives.nd.edu/Football/Football.htm')\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# isolate HTML with 'ol' tag\n",
    "url_names = soup.find('ol')\n",
    "\n",
    "# find all instances of 'a' tag\n",
    "items = url_names.find_all('a')\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Publication Links and Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list for urls\n",
    "url_list = []\n",
    "\n",
    "# create empty list for publication titles\n",
    "title_list = []\n",
    "\n",
    "# for loop that extracts href contents, concatenates full url, appends to url_list; extracts tag contents (publication title) and appends to title_list\n",
    "for item in items:\n",
    "    url_list.append(\"http://archives.nd.edu/Football/\" + item.get('href'))\n",
    "    title_list.append(item.contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show list of urls\n",
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show list of publication titles\n",
    "title_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download PDFs from List of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import urllib3\n",
    "import os\n",
    "\n",
    "# configure urllib\n",
    "http = urllib3.PoolManager()\n",
    "print(\"downloading with urllib\")\n",
    "\n",
    "# for loop that downloads PDFs\n",
    "for url in url_list:\n",
    "    r = http.request('GET', url)\n",
    "    filename = os.path.basename(url)\n",
    "    with open (filename, 'wb') as fcont:\n",
    "        fcont.write(r.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching File Names and Publication Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list for file names\n",
    "file_names = []\n",
    "\n",
    "# for loop that extracts href contents, appends to file_name list\n",
    "for item in items:\n",
    "    file_names.append(item.get('href'))\n",
    "\n",
    "# show file_names list\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# create empty dataframe with two columns\n",
    "df = pd.DataFrame(columns=['file_name', 'title'])\n",
    "\n",
    "# append url_list to file_names column\n",
    "df['file_name'] = file_names\n",
    "\n",
    "# append file_name_list to title column\n",
    "df['title'] = title_list\n",
    "\n",
    "# show dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to csv file\n",
    "df.to_csv('scholastic_file_name_master.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
