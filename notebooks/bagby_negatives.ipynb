{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Notre Dame Bagby Negative Images\n",
    "\n",
    "From the [University Archives](http://archives.nd.edu/digital/):\n",
    "- \"The Bagby company, a South Bend photographic studio, took pictures of athletes for Notre Dame. The digitized Glass Plate Negative Collection is part of a [larger Bagby collection](http://archives.nd.edu/findaids/ead/xml/bby.xml).\"\n",
    "- [Bagby Glass Plate Negative Collection (Notre Dame Sports), 1920s-1930s](http://archives.nd.edu/Bagby/index.htm)\n",
    "\n",
    "This Jupyter Notebook inclues codes + comments that downloads all images in the Bagby Glass Plate Negative Collection (Notre Dame Sports), and also matches image metadata to file names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries, Load URL, and Create Beautiful Soup Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load url, create beautifulsoup object\n",
    "page = requests.get('http://archives.nd.edu/Bagby/index.htm')\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# isolate html with 'table' tag\n",
    "url_names = soup.find('table')\n",
    "\n",
    "# find all instances of 'img' tag\n",
    "img_list = url_names.find_all('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Image File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list for image file names\n",
    "image_file_names = []\n",
    "\n",
    "# for loop that isolates src contents, removes 'tn\\\\' string, and appends to empty list\n",
    "for img in img_list:\n",
    "    image_file_names.append(img.get('src').replace(\"tn\\\\tn-\", \"\"))\n",
    "    \n",
    "# list of image file names\n",
    "image_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Image URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list for image urls\n",
    "image_url_list = []\n",
    "\n",
    "# for loop that concatenates URL root with image file name (end of link)\n",
    "for name in image_file_names:\n",
    "    image_url_list.append(\"http://archives.nd.edu/Bagby/\" + name)\n",
    "    \n",
    "# list of urls\n",
    "image_url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Image Files from List of Full URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import urllib3\n",
    "import os\n",
    "\n",
    "# configure urllib\n",
    "http = urllib3.PoolManager()\n",
    "print(\"downloading with urllib\")\n",
    "\n",
    "# for loop that downloads image for each url in image_url_list\n",
    "for url in image_url_list:\n",
    "    r = http.request('GET', url)\n",
    "    filename = os.path.basename(url)\n",
    "    with open (filename, 'wb') as fcont:\n",
    "        fcont.write(r.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching File Names and Image Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show table object\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from table object usign pd.read_html\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "# show newly-created dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map image file names to image description\n",
    "\n",
    "# rename second column \n",
    "df.rename(columns={1: 'image_title'}, inplace=True)\n",
    "\n",
    "# delete first column\n",
    "del df[0]\n",
    "\n",
    "# show updated dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new file_name column with values from image_file_names list\n",
    "df['file_name'] = image_file_names\n",
    "\n",
    "# show updated dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to csv\n",
    "df.to_csv('bagby_images_file_name_master.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
