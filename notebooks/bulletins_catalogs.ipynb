{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Notre Dame Annual Catalogues and Bulletins\n",
    "\n",
    "From the [University Archives](http://archives.nd.edu/digital/):\n",
    "- \"Notre Dame's catalogues or bulletins included descriptions of courses, programs, curricula, facilities, and faculty. They generally [listed students](http://archives.nd.edu/bulletin/stdnts.htm) and provided information on [graduation ceremonies](http://archives.nd.edu/bulletin/cmmncmts.htm), degree recipients, and academic prizes won by students.\"\n",
    "- [Notre Dame Annual Catalogues or Bulletins, 1850 - 1914](http://archives.nd.edu/bulletin/)\n",
    "\n",
    "This Jupyter Notebook inclues codes + comments that downloads all PDFs ofr Notre Dame annual catalogues and bulletins, and also matches document titles to file names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries, Load URL, and Create Beautiful Soup Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load url, create beautifulsoup object\n",
    "page = requests.get('http://archives.nd.edu/bulletin/catalogs.htm')\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# isolate HTML with 'ul' tag\n",
    "file_names = soup.find('ul')\n",
    "\n",
    "# find all instances of 'a' tag\n",
    "items = file_names.find_all('a')\n",
    "\n",
    "# show items\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Publication Links and Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty list for urls\n",
    "url_list = []\n",
    "\n",
    "# empty list for publication titles\n",
    "title_list = []\n",
    "\n",
    "# for loop that extracts href contents, concatenates with url root, appends to url_list; extracts publication title and appends to title_list \n",
    "for item in items:\n",
    "    url_list.append(\"http://archives.nd.edu/bulletin/\" + item.get('href'))\n",
    "    title_list.append(item.contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show list of urls\n",
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show list of titles\n",
    "title_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download PDFs from List of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import urllib3\n",
    "import os\n",
    "\n",
    "# configure urllib\n",
    "http = urllib3.PoolManager()\n",
    "print(\"downloading with urllib\")\n",
    "\n",
    "# for loop that downloads PDF for each url in url_list\n",
    "for url in url_list:\n",
    "    r = http.request('GET', url)\n",
    "    filename = os.path.basename(url)\n",
    "    with open (filename, 'wb') as fcont:\n",
    "        fcont.write(r.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching File Names and Publication Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list for file names\n",
    "file_names = []\n",
    "\n",
    "# for loop that extracts href contents, appends to file_name list\n",
    "for item in items:\n",
    "    file_names.append(item.get('href'))\n",
    "\n",
    "# show file_names list\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(columns=['file_name', 'title'])\n",
    "\n",
    "# write file names to column\n",
    "df['file_name'] = file_names\n",
    "\n",
    "# write publication titles to column\n",
    "df['title'] = title_list\n",
    "\n",
    "# output dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cleaned Version of Publication Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import re\n",
    "import string\n",
    "\n",
    "  \n",
    "# create variable with punctuation/special characters\n",
    "rem = string.punctuation\n",
    "pattern = r\"[{}]\".format(rem)\n",
    "\n",
    "# create title_clean column in dataframe and use regular expressions to replace special characters\n",
    "df['title_clean'] = df['title'].str.replace(pattern, \"-\")\n",
    "\n",
    "# remove any remaining whitespace\n",
    "df['title_clean'] = df['title_clean'].str.replace(\" \", \"-\")\n",
    "\n",
    "# remove double dashes\n",
    "df['title_clean'] = df['title_clean'].str.replace(\"--\", \"-\")\n",
    "\n",
    "# remove double dashes again\n",
    "df['title_clean'] = df['title_clean'].str.replace(\"--\", \"-\")\n",
    "\n",
    "# remove trailing dash\n",
    "df['title_clean'] = df['title_clean'].str.replace(\"-$\", \"\")\n",
    "\n",
    "# show updated dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write DataFrame to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to csv file\n",
    "df.to_csv('bulletins_catalogs_name_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename PDFs\n",
    "\n",
    "Code that renames downloaded files with respective publication title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import os\n",
    "\n",
    "# create dictionary file file_name and clean_title columns in dataframe\n",
    "references = dict(df.set_index(\"file_name\")[\"title_clean\"])\n",
    "\n",
    "# show dictionary\n",
    "references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for loop that isolates dictionary elements and renames PDFs\n",
    "for item in references.items():\n",
    "    try:\n",
    "        old_name = item[0]\n",
    "        new_name = (item[1] + \".pdf\")\n",
    "        os.rename(old_name, new_name)\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
