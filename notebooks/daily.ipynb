{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Notre Dame Daily PDFs\n",
    "\n",
    "From the [University Archives](http://archives.nd.edu/digital/):\n",
    "- \"The Notre Dame Daily first appeared on the twentieth of May, 1923. It published thirteen issue in its first volume, concluding at the end of the academic year on the sixth of June. Its second and final volume covered the 1923-1924 academic year in 128 issues beginning on the twenty-third of September and ending on the fifteenth of June.\"\n",
    "- [Notre Dame Daily (student newspaper), 1923 - 1924](http://archives.nd.edu/Daily/)\n",
    "\n",
    "This Jupyter Notebook inclues codes + comments that downloads all PDFs of *The Notre Dame Daily*, and also matches issue titles to file names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries, Load URL, and Create Beautiful Soup Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load url, create beautifulsoup object\n",
    "page = requests.get('http://archives.nd.edu/Daily/Daily.htm')\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# isoalte HTML with 'ol' tag\n",
    "url_names = soup.find('ol')\n",
    "\n",
    "# find all instances of 'a' tag\n",
    "items = url_names.find_all('a')\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get List of Issue Titles and Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list for urls\n",
    "url_list = []\n",
    "\n",
    "# create empty list for issue titles\n",
    "title_list = []\n",
    "\n",
    "# for loop that extracts href contents, concatenates full url, appends to url_list; extracts tag contents (issue title) and appends to title_list\n",
    "    url_list.append(\"http://archives.nd.edu/Daily/\" + item.get('href'))\n",
    "    title_list.append(item.contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show url list\n",
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show title list\n",
    "title_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download PDFs from List of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import urllib3\n",
    "import os\n",
    "\n",
    "# configure urllib\n",
    "http = urllib3.PoolManager()\n",
    "print(\"downloading with urllib\")\n",
    "\n",
    "# for loop that downloads PDFs\n",
    "for url in url_list:\n",
    "    r = http.request('GET', url)\n",
    "    filename = os.path.basename(url)\n",
    "    with open (filename, 'wb') as fcont:\n",
    "        fcont.write(r.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching File Names and Issue Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list for file names\n",
    "file_names = []\n",
    "\n",
    "# for loop that extracts href contents, appends to file_names list\n",
    "for item in items:\n",
    "    file_names.append(item.get('href'))\n",
    "\n",
    "# show file_names list\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# create empty dataframe with two columns\n",
    "df = pd.DataFrame(columns=['file_name', 'title'])\n",
    "\n",
    "# append url_list to file_names column\n",
    "df['file_name'] = file_names\n",
    "\n",
    "# append file_name_list to title column\n",
    "df['title'] = title_list\n",
    "\n",
    "# show dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to csv\n",
    "df.to_csv('daily_file_name_master.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
