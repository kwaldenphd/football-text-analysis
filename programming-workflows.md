# Lab #1: Text Analysis, Programming Workflows

<a href="http://creativecommons.org/licenses/by-nc/4.0/" rel="license"><img style="border-width: 0;" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" alt="Creative Commons License" /></a>
This tutorial is licensed under a <a href="http://creativecommons.org/licenses/by-nc/4.0/" rel="license">Creative Commons Attribution-NonCommercial 4.0 International License</a>.

# Oh, the Places You Could Go!

In addition to the graphical-user-interface (GUI) based tools covered in the previous sections of the lab, we can also apply these methods using programmatic workflows.

 - [NLTK and Python](#nltk-and-python)
 - [Natural Language Processing and Text Analysis in R](#natural-langauge-processing-and-text-analysis-in-r)
 - [Topic Modeling](#topic-modeling)
 - [Named Entity Extraction](#named-entity-extraction)
 - [Distant Reader](#distant-reader)

## NLTK and Python

To undertake large-scale text analysis, we would need to be able to download source material in bulk and eventually convert that source material to plain-text formats for various kinds of analysis and visualization in a programming environment. This section of the lab procedure includes Jupyter notebook (`.ipynb`) files with sample Python workflows for using text and data mining workflows with select collections of digitized material from the [University of Notre Dame Archives](http://archives.nd.edu/).

[Link to this section of the lab](https://github.com/kwaldenphd/football-text-analysis/blob/main/python-text-analysis.md)

## Natural Language Processing and Text Analysis in R

Taylor Arnold and Lauren Tilton (2015), [*Humanities Data in R: Exploring Networks, Geospatial Data, Images, and Text*](https://onesearch.library.nd.edu/permalink/f/1phik6l/ndu_aleph005141805). Springer.
- [Supplementary material](https://humanitiesdata.org/)

[CRAN Task View: Natural Language Processing](https://cran.r-project.org/web/views/NaturalLanguageProcessing.html)

*Programming Historian* tutorials:
- [Basic text processing](https://programminghistorian.org/en/lessons/basic-text-processing-in-r)
- [Sentiment analysis](https://programminghistorian.org/en/lessons/sentiment-analysis-syuzhet)

## Topic Modeling

*Programming Historian* [Topic Modeling & MALLET tutorial](https://programminghistorian.org/en/lessons/topic-modeling-and-mallet)

[Prof. Walden's tutorial](https://github.com/kwaldenphd/topicmodeling-tutorial)

[Link to download Stanford's Topic Modeling Tool](https://downloads.cs.stanford.edu/nlp/software/tmt/tmt-0.3)

## Named Entity Extraction 

[Prof. Walden's tutorial](https://github.com/kwaldenphd/NLP-NER-tutorial)

[Link to download Stanford's Named Entity Recognition tool](https://nlp.stanford.edu/software/CRF-NER.shtml)

## Distant Reader

"The Distant Reader takes text as input, does analysis against it, and outputs sets of structured data called 'study carrels', which students, researchers, or scholars can use to do both close and distant reading...[it is] a tool intended to supplement the traditional reading process. Given a set of one or more texts acquired through a variety of means, the Reader: 1) applies different forms of text mining and natural language processing against the texts, 2) saves the results as a set of structured data amenable to computing, 3) summarizes everything in a set of interactive HTML reports, 4) compresses everything into a .zip file, and 5) provides the means for you to view the results online or download the whole thing to your computer. This resulting .zip file is affectionately called a 'study carrels."
- Morgan, Eric Lease. (2020, April 10). Distant Reader (Version Alpha). Zenodo. https://doi.org/10.5281/zenodo.3747777.

To learn more about Distant Reader:
- [About](https://distantreader.org/)
- [Getting Started](https://reader-toolbox.readthedocs.io/en/latest/)
